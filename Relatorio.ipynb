{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section-0\"></a>\n",
    "<img src=\"https://i.imgur.com/lTCPbz0.jpeg\" alt='logo puc-sp' width='30%' align='left'>\n",
    "\n",
    "### Pontifícia Universidade Católica de São Paulo (PUC-SP)\n",
    "\n",
    "<h1 style=font-size:30px>TrendSpotter: O Poder das Palavras-chave</h1>\n",
    "\n",
    "\n",
    "### Bacharelado em Ciência de Dados e Inteligência Artificial\n",
    "\n",
    "#### Turma: CDIA21-MA\n",
    "\n",
    "**Professor:** Eduardo Savino Gomes\n",
    "\n",
    "### Integrantes\n",
    "\n",
    "<table align=\"left\" style=font-size:15px>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th style=\"text-align:left;\">Nome</th>\n",
    "    <th style=\"text-align:left;\">RA</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td style=\"text-align:left;\">Heloisa Mariani Rodrigues</td>\n",
    "    <td>RA00297685</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:left;\">João Pedro Taves Araujo</td>\n",
    "    <td>RA00297753</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:left;\">Lucas Lopes Amorim</td>\n",
    "    <td>RA00303799</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:left;\">Lucca Cerf Costa</td>\n",
    "    <td>RA00304770</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:left;\">Simeon Chavdar Ivanov</td>\n",
    "    <td>RA00297777</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapando artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Exemplo de uso com alguns scrapers\n",
    "\n",
    "from src.Extractors import CanalTechScraper, OlharDigitalScraper, TecMundoScraper, TudoCelularScraper\n",
    "\n",
    "#criando lista de extratores e rodando todos em um loop\n",
    "extractors = [CanalTechScraper(), OlharDigitalScraper(), TecMundoScraper(), TudoCelularScraper()]\n",
    "for extractor in extractors:\n",
    "    extractor.get_articles(save=True)\n",
    "\n",
    "###Todos os dados serão salvos como json na pasta data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contar palavras de artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, col, desc, lit, explode\n",
    "import glob\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"WordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>WordCount</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f713eea12d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo dados dos artigos raspados e excluindo desse processamento os dados do twitter (rede social)\n",
    "file_paths = glob.glob('./src/clean_data/*json')\n",
    "file_paths.remove('./src/clean_data/Twitter_clean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(file_path, top_n_words=30):\n",
    "    \"\"\"\n",
    "    Conta a frequência de palavras de um arquivo\n",
    "    json e seleciona as top_n_wordsmais frequentes.\n",
    "    \"\"\"\n",
    "    file_name = file_path.split('/')[-1].split('.')[0]\n",
    "    df = spark.read.json(file_path)\n",
    "    df_words = df.withColumn(\"words\", split(df.text, \"\\s+\"))\n",
    "    df_exploded = df_words.select(df_words.link, explode(df_words.words).alias(\"word\"))\n",
    "    word_counts = df_exploded.groupBy(\"word\").count()\n",
    "    word_counts_sorted = word_counts.orderBy(word_counts[\"count\"].desc()).limit(top_n_words)\n",
    "    site_word_counts = word_counts_sorted.withColumn(\"site\", lit(file_name))\n",
    "    return site_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando CanalTech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando G1\n",
      "Processando ITForum\n",
      "Processando TecMundo\n",
      "Processando TudoCelular\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file_ in file_paths:\n",
    "    file_name = file_.split('/')[-1].split('.')[0]\n",
    "    print(f'Processando {file_name}')\n",
    "    word_counts = count_words(file_)\n",
    "    dfs.append(word_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unindo todos os DataFrames em um só"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    result_df = result_df.union(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---------+\n",
      "|        word|count|     site|\n",
      "+------------+-----+---------+\n",
      "|     AirPods|   84|CanalTech|\n",
      "|       Apple|   50|CanalTech|\n",
      "|         Pro|   45|CanalTech|\n",
      "|           2|   28|CanalTech|\n",
      "|      estojo|   22|CanalTech|\n",
      "|      ouvido|   21|CanalTech|\n",
      "|      iPhone|   20|CanalTech|\n",
      "|carregamento|   20|CanalTech|\n",
      "|       fones|   18|CanalTech|\n",
      "|        fone|   17|CanalTech|\n",
      "|     bateria|   16|CanalTech|\n",
      "|        USBC|   14|CanalTech|\n",
      "|        novo|   14|CanalTech|\n",
      "|       Passo|   14|CanalTech|\n",
      "|       Beats|   12|CanalTech|\n",
      "|          TV|   12|CanalTech|\n",
      "|      volume|   12|CanalTech|\n",
      "|         Fit|   11|CanalTech|\n",
      "|       áudio|   11|CanalTech|\n",
      "|        deve|   11|CanalTech|\n",
      "+------------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduza o número de partições para 1\n",
    "result_df = result_df.coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Salvando em CSV\n",
    "result_df.write.csv(\"./src/output/word_counts.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando rede social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Extractors import SocialMediaScraper\n",
    "\n",
    "# Obtendo dados do twitter\n",
    "# é necessário logar na conta para que o site usado para o scraping seja carregado\n",
    "twitter_scraper = SocialMediaScraper(login, senha)\n",
    "twitter_scraper.get_tweets(save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contando palavras de rede social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, size\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_social_media(file_path, top_n_words=30):\n",
    "    \"\"\"\n",
    "    Conta a frequência de palavras de um arquivo\n",
    "    json, seleciona as top_n_wordsmais frequentes e \n",
    "    \"\"\"\n",
    "    file_name = file_path.split('/')[-1].split('.')[0]\n",
    "    df = spark.read.json(file_path)\n",
    "    \n",
    "    df = df.withColumn(\"sentiment\", when(col(\"sentiment\") == \"Positive\", 1)\n",
    "                                .when(col(\"sentiment\") == \"Neutral\", 0)\n",
    "                                .when(col(\"sentiment\") == \"Negative\", -1))\n",
    "    df_words = df.withColumn(\"words\", split(df.text, \"\\s+\"))\n",
    "    df_exploded = df_words.select(\"sentiment\", F.explode(\"words\").alias(\"word\"))\n",
    "\n",
    "    word_counts = df_exploded.groupBy(\"word\").count()\n",
    "    sentiment_avg = df_exploded.groupBy(\"word\").agg(F.avg(\"sentiment\").alias(\"sentiment_avg\"))\n",
    "    df_final = word_counts.join(sentiment_avg, \"word\", \"inner\")\n",
    "    df_final_sorted = df_final.orderBy(df_final[\"count\"].desc()).limit(30)\n",
    "\n",
    "    return df_final_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_net_path = './src/clean_data/Twitter_clean.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = count_words_social_media(social_net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                 (0 + 1) / 1][Stage 61:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------------------+\n",
      "|   word|count|      sentiment_avg|\n",
      "+-------+-----+-------------------+\n",
      "|AirPods|   16|             -0.375|\n",
      "|airpods|   10|               -0.1|\n",
      "|    Pro|    9|-0.3333333333333333|\n",
      "|      2|    6|-0.3333333333333333|\n",
      "|    pra|    5|                0.0|\n",
      "|  Apple|    5|               -0.2|\n",
      "|   fone|    4|              -0.75|\n",
      "|comprar|    3|               -1.0|\n",
      "|      É|    3|-0.3333333333333333|\n",
      "| ouvido|    3|-0.6666666666666666|\n",
      "|      R|    3|                0.0|\n",
      "|Airpods|    3| 0.6666666666666666|\n",
      "|  perdi|    3|               -1.0|\n",
      "|  Dolby|    2|               -1.0|\n",
      "|      O|    2|                0.0|\n",
      "|  preto|    2|               -0.5|\n",
      "|    max|    2|                0.0|\n",
      "|   vida|    2|                1.0|\n",
      "|    pro|    2|                0.0|\n",
      "| chique|    2|               -1.0|\n",
      "+-------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "twitter_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendamos um site para anunciar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pensando na utilização do nosso serviço em um cenário real de Big Data, pensamos em utilizar ferramentas como o ChatGPT para analisar os dados coletados e realizar a recomendação dos ssites para nós.\n",
    "\n",
    "- O modelo utilizou um cálculo de similaridade de palavras, cruzando os dados de redes sociais com os dos sites para embasar a recomendação:\n",
    "\n",
    "| Site        | Contagem de Palavras Correspondentes | Similaridade |\n",
    "|-------------|--------------------------------------|--------------|\n",
    "| CanalTech   | 84 + 24 + 17 + 3 = 128                                  | 128/87 = 1.47         |\n",
    "| G1          | 24 + 17 + 4 + 3 + 5 + 5 + 16 + 9 + 3 + 3 = 89                                   |89/87 = 1.02         |\n",
    "| ITForum     | 91                                   | 91/87 = 1.05         |\n",
    "| TecMundo    | 145 + 81 + 59 + 16 + 50 + 23 + 13 + 18 =  405                                  | 405/87 = 4.66         |\n",
    "| TudoCelular | 16 + 122 + 9 + 6 + 29 + 18 + 3 =  203                                  | 203/87 = 2.33         |\n",
    "\n",
    "\n",
    "Portanto, fica claro que com os dados que temos, TecMundo seria o site mais favorável à indicação.\n",
    "\n",
    "Ao pedir que o modelo elaborasse mais na recomendação, conseguimos o seguinte resultado:\n",
    "\n",
    "1. Similaridade de conteúdo: O TecMundo obteve a maior pontuação de similaridade com o conteúdo sendo compartilhado sobre os AirPods no Twitter. Isso indica que o site está abordando tópicos relacionados aos AirPods de maneira mais abrangente e em linha com as conversas nas redes sociais. Ao anunciar nesse site, há uma maior probabilidade de atingir o público interessado no produto.\n",
    "\n",
    "2. Audiência especializada: O TecMundo é conhecido por seu foco em tecnologia e por atrair uma audiência especializada nesse assunto. Ao anunciar os AirPods em um site voltado para tecnologia, é mais provável que você alcance pessoas que estejam ativamente buscando informações e avaliações sobre produtos desse segmento. Isso aumenta as chances de atingir consumidores interessados nos AirPods e potenciais compradores.\n",
    "\n",
    "3. Relevância e autoridade: O TecMundo é reconhecido como uma fonte confiável de informações sobre tecnologia. Ao associar sua marca e produtos a um site respeitado e confiável, você pode aumentar a percepção de qualidade e confiança dos seus produtos. Além disso, o TecMundo possui uma base de leitores fiéis que acompanham regularmente o conteúdo do site, o que significa que seus anúncios terão visibilidade entre um público engajado.\n",
    "\n",
    "4. Alcance e visibilidade: O TecMundo é um dos sites de tecnologia mais populares do Brasil, alcançando um grande número de leitores e seguidores. Ao anunciar os AirPods nesse site, você terá a oportunidade de alcançar uma ampla audiência interessada em tecnologia, incluindo potenciais compradores que estão em busca de informações sobre fones de ouvido sem fio.\n",
    "\n",
    "Em resumo, escolher o TecMundo para posicionar os anúncios dos AirPods oferece a vantagem de estar em um site com conteúdo alinhado ao interesse do público, uma audiência especializada em tecnologia, uma fonte confiável de informações e um grande alcance para aumentar a visibilidade do produto. Esses fatores combinados podem contribuir para o sucesso da campanha de marketing e para alcançar o público certo para os AirPods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apresentando resultados em um Dashboard do Tableau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <a href=\"https://public.tableau.com/views/WordCount_16871324744110/Dashboard\"><img alt=\"Nuvem de Palavras\" width=\"75%\" src=\"img/dashboard.png\" /></a>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
